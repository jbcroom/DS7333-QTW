#### 2011
women_2011_lst <- womenTables[13]
women_2011_lst <- lapply(women_2011_lst, function(x) {x[c(-1:-4)]})
RecordCount_df[nrow(RecordCount_df) + 1,] = c("2011",lengths(women_2011_lst))
#lengths(women_2011_lst) # 9034
# Convert to dataframe
women_2011_t = as.data.frame(women_2011_lst)
women_2011_df <- data.frame(Place = substr(women_2011_t[5:9034,],1,5),
DivTot =substr(women_2011_t[5:9034,],7,17),
Num =substr(women_2011_t[5:9034,],19,24),
Name =substr(women_2011_t[5:9034,],26,47),
Ag =substr(women_2011_t[5:9034,],49,50),
Hometown =substr(women_2011_t[5:9034,],52,71),
Five_Mile =substr(women_2011_t[5:9034,],73,79),
Time =substr(women_2011_t[5:9034,],81,87),
NetTime =substr(women_2011_t[5:9034,],89,96),
Pace =substr(women_2011_t[5:9034,],98,101),
S =substr(women_2011_t[5:9034,],103,103))
### 2012
women_2012_lst <- womenTables[14]
women_2012_lst <- lapply(women_2012_lst, function(x) {x[c(-1,-2,-3,-4)]})
RecordCount_df[nrow(RecordCount_df) + 1,] = c("2012",lengths(women_2012_lst))
#lengths(women_2012_lst) # 9733
# Convert to dataframe
women_2012_t = as.data.frame(women_2012_lst)
women_2012_df <- data.frame(Place = substr(women_2012_t[5:9733,],1,5),
DivTot =substr(women_2012_t[5:9733,],7,17),
Num =substr(women_2012_t[5:9733,],19,24),
Name =substr(women_2012_t[5:9733,],26,47),
Ag =substr(women_2012_t[5:9733,],49,50),
Hometown =substr(women_2012_t[5:9733,],52,71),
Five_Mile =substr(women_2012_t[5:9733,],73,79),
Time =substr(women_2012_t[5:9733,],81,87),
Pace =substr(women_2012_t[5:9733,],89,93),
S =substr(women_2012_t[5:9733,],95,95))
as.data.table(RecordCount_df)
sapply(women_2000_df,class)
MissingCount_df <- data.frame(matrix(ncol = 2, nrow = 0))
x <- c("Year", "Count")
colnames(MissingCount_df) = x
MissingCount_df[nrow(MissingCount_df) + 1,] = c("1999",sum(is.na(women_1999_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2000",sum(is.na(women_2000_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2001",sum(is.na(women_2001_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2002",sum(is.na(women_2002_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2003",sum(is.na(women_2003_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2004",sum(is.na(women_2004_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2005",sum(is.na(women_2005_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2006",sum(is.na(women_2006_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2007",sum(is.na(women_2007_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2008",sum(is.na(women_2008_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2009",sum(is.na(women_2009_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2010",sum(is.na(women_2010_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2011",sum(is.na(women_2011_df)))
MissingCount_df[nrow(MissingCount_df) + 1,] = c("2012",sum(is.na(women_2012_df)))
as.data.table(MissingCount_df)
# Function to convert time to a decimal so we can interpret it
convertTime = function(time) {
timePieces = strsplit(time, ":")
timePieces = sapply(timePieces, as.numeric)
sapply(timePieces, function(x) {
if (length(x) == 2) x[1] + x[2]/60
else 60*x[1] + x[2] + x[3]/60
})
}
# Time / 10 = pace
# Combine all dataframes into a single common dataframe
women_1999_df[,"Year"] <- "1999"
women_1999_df[,"Net"] <- women_1999_df[,"Time"]
women_1999_df <- women_1999_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_1999_df$Ag <- as.numeric(women_1999_df$Ag)
# Time conversion
women_1999_df$Net <- as.character(women_1999_df$Net)
women_1999_df$Net_Conv = convertTime(women_1999_df$Net)
women_1999_df <- na.omit(women_1999_df)
women_2000_df[,"Year"] <- "2000"
women_2000_df[,"Pace"] <- "0"
women_2000_df <- women_2000_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2000_df$Ag <- as.numeric(women_2000_df$Ag)
# Time conversion
women_2000_df$Net <- as.character(women_2000_df$Net)
women_2000_df$Net_Conv = convertTime(women_2000_df$Net)
women_2000_df <- na.omit(women_2000_df)
women_2001_df[,"Year"] <- "2001"
women_2001_df[,"DivTot"] <- "0"
women_2001_df[,"Pace"] <- "0"
women_2001_df <- women_2001_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2001_df$Ag <- as.numeric(women_2001_df$Ag)
# Time conversion
women_2001_df$Net <- as.character(women_2001_df$Net)
women_2001_df$Net_Conv = convertTime(women_2001_df$Net)
women_2001_df <- na.omit(women_2001_df)
women_2002_df[,"Year"] <- "2002"
women_2002_df[,"DivTot"] <- "0"
women_2002_df[,"Pace"] <- "0"
women_2002_df <- women_2002_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2002_df$Ag <- as.numeric(women_2002_df$Ag)
# Time conversion
women_2002_df$Net <- as.character(women_2002_df$Net)
women_2002_df$Net_Conv = convertTime(women_2002_df$Net)
women_2002_df <- na.omit(women_2002_df)
women_2003_df[,"Year"] <- "2003"
women_2003_df[,"Pace"] <- "0"
women_2003_df[,"Net"] <- women_2003_df[,"NetTime"]
women_2003_df <- women_2003_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2003_df$Ag <- as.numeric(women_2003_df$Ag)
# Time conversion
women_2003_df$Net <- as.character(women_2003_df$Net)
women_2003_df$Net_Conv = convertTime(women_2003_df$Net)
women_2003_df <- na.omit(women_2003_df)
women_2004_df[,"Year"] <- "2004"
women_2004_df[,"Pace"] <- "0"
women_2004_df <- women_2004_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2004_df$Ag <- as.numeric(women_2004_df$Ag)
# Time conversion
women_2004_df$Net <- as.character(women_2004_df$Net)
women_2004_df$Net_Conv = convertTime(women_2004_df$Net)
women_2004_df <- na.omit(women_2004_df)
women_2005_df[,"Year"] <- "2005"
women_2005_df <- women_2005_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2005_df$Ag <- as.numeric(women_2005_df$Ag)
# Time conversion
women_2005_df$Net <- as.character(women_2005_df$Net)
women_2005_df$Net_Conv = convertTime(women_2005_df$Net)
women_2005_df <- na.omit(women_2005_df)
women_2006_df[,"Year"] <- "2006"
women_2006_df[,"Net"] <- women_2006_df[,"NetTime"]
women_2006_df <- women_2006_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2006_df$Ag <- as.numeric(women_2006_df$Ag)
# Time conversion
women_2006_df$Net <- as.character(women_2006_df$Net)
women_2006_df$Net_Conv = convertTime(women_2006_df$Net)
women_2006_df <- na.omit(women_2006_df)
women_2007_df[,"Year"] <- "2007"
women_2007_df[,"Net"] <- women_2007_df[,"Time"]
women_2007_df <- women_2007_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2007_df$Ag <- as.numeric(women_2007_df$Ag)
# Time conversion
women_2007_df$Net <- as.character(women_2007_df$Net)
women_2007_df$Net_Conv = convertTime(women_2007_df$Net)
women_2007_df <- na.omit(women_2007_df)
women_2008_df[,"Year"] <- "2008"
women_2008_df[,"Pace"] <- women_2008_df[,"Pace3"]
women_2008_df[,"Net"] <- women_2008_df[,"Time"]
women_2008_df <- women_2008_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2008_df$Ag <- as.numeric(women_2008_df$Ag)
# Time conversion
women_2008_df$Net <- as.character(women_2008_df$Net)
women_2008_df$Net_Conv = convertTime(women_2008_df$Net)
women_2008_df <- na.omit(women_2008_df)
women_2009_df[,"Year"] <- "2009"
women_2009_df[,"Net"] <- women_2009_df[,"NetTime"]
women_2009_df <- women_2009_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2009_df$Ag <- as.numeric(women_2009_df$Ag)
# Time conversion
women_2009_df$Net <- as.character(women_2009_df$Net)
women_2009_df$Net_Conv = convertTime(women_2009_df$Net)
women_2009_df <- na.omit(women_2009_df)
women_2010_df[,"Year"] <- "2010"
women_2010_df[,"Net"] <- women_2010_df[,"NetTime"]
women_2010_df <- women_2010_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2010_df$Ag <- as.numeric(women_2010_df$Ag)
# Time conversion
women_2010_df$Net <- as.character(women_2010_df$Net)
women_2010_df$Net_Conv = convertTime(women_2010_df$Net)
women_2010_df <- na.omit(women_2010_df)
women_2011_df[,"Year"] <- "2011"
women_2011_df[,"Net"] <- women_2011_df[,"Time"]
women_2011_df <- women_2011_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2011_df$Ag <- as.numeric(women_2011_df$Ag)
# Time conversion
women_2011_df$Net <- as.character(women_2011_df$Net)
women_2011_df$Net_Conv = convertTime(women_2011_df$Net)
women_2011_df <- na.omit(women_2011_df)
women_2012_df[,"Year"] <- "2012"
women_2012_df[,"Net"] <- women_2012_df[,"Time"]
women_2012_df <- women_2012_df[,c("Year","Place","DivTot","Name","Ag","Hometown","Net","Pace")]
women_2012_df$Ag <- as.numeric(women_2012_df$Ag)
# Time conversion
women_2012_df$Net <- as.character(women_2012_df$Net)
women_2012_df$Net_Conv = convertTime(women_2012_df$Net)
women_2012_df <- na.omit(women_2012_df)
# Combined women dataframe
women_combined_df <- bind_rows(women_1999_df
,women_2000_df
,women_2001_df
,women_2002_df
,women_2003_df
,women_2004_df
,women_2005_df
,women_2006_df
,women_2007_df
,women_2008_df
,women_2009_df
,women_2010_df
,women_2011_df
,women_2012_df)
sapply(women_combined_df, class)
MissCount_df <- data.frame(matrix(ncol = 1, nrow = 0))
x <- c("Count Missing")
colnames(MissCount_df) = x
MissCount_df[nrow(MissCount_df) + 1,] = c(sum(is.na(women_combined_df)))
as.data.table(MissCount_df)
summary(women_combined_df)
women_combined_df[which(women_combined_df$Ag == min(women_combined_df$Ag)), ]]
women_combined_df[which(women_combined_df$Ag == min(women_combined_df$Ag)), ]
ggplot(women_combined_df, aes(x=Year, y=Ag)) +
geom_boxplot(outlier.colour="red", outlier.shape=8,
outlier.size=4) +
ggtitle("Women's Racers Ages - All Years")
ggplot(women_combined_df) +
geom_density(aes(x = Ag), alpha = 0.7,color="green", fill="lightgreen") +
ggtitle("Women's Racers Age Distribution - All Years") +
geom_vline(aes(xintercept=mean(Ag)), color="red", linetype="dashed", size=1)
MeanAge_df <- data.frame(matrix(ncol = 2, nrow = 0))
x <- c("Year", "Mean Age")
colnames(MeanAge_df) = x
MeanAge_df[nrow(MeanAge_df) + 1,] = c("1999",mean(women_1999_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2000",mean(women_2000_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2001",mean(women_2001_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2002",mean(women_2002_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2003",mean(women_2003_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2004",mean(women_2004_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2005",mean(women_2005_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2006",mean(women_2006_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2007",mean(women_2007_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2008",mean(women_2008_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2009",mean(women_2009_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2010",mean(women_2010_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2011",mean(women_2011_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("2012",mean(women_2012_df$A))
MeanAge_df[nrow(MeanAge_df) + 1,] = c("Total",mean(women_combined_df$Ag))
as.data.table(MeanAge_df)
# get total count of racers in 2006
nrow(women_2006_df)
# get number of racers under the mean of 32
nrow((women_2006_df[which(women_2006_df$Ag < 32), ]))
# If we re-plot the age distribution and ignore all ages younger than 18 due to the 2006 outlier, we get this distribution
# There is some evidence that racers' ages are getting younger, but take note of the two outlier years in 2007 and 2002 where
# ages were a bit older
Year_Sel <- c('1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012')
women_combined_df %>%
filter(Ag > 18 & Year == Year_Sel) %>%
ggplot() +
geom_density(aes(x = Ag,group = factor(Year), fill=factor(Year), alpha = 0.5)) +
ggtitle("Women's Racers Age Distribution - All Years - Distribution") +
labs(fill = "Year") +
geom_vline(aes(xintercept=mean(Ag)), color="red", linetype="dashed", size=1)
# Scatter Plot - this plot, filtered for ages > 18, clearly shows a stronger concentration of ages in the 2009 - 2012 year range compared
# to previous years
women_combined_df %>%
filter(Ag > 18 & Year == Year_Sel) %>%
ggplot(map=aes(Year,Ag))+
geom_point()+
geom_jitter() +
ggtitle("Women's Racers Ages - All Years - Scatter Plot")
# Box Plots - Net Race Times
# Mean times are increasing - big outlier in 2011
ggplot(women_combined_df, aes(x=Year, y=Net_Conv)) +
geom_boxplot(outlier.colour="red", outlier.shape=8,
outlier.size=4) +
ggtitle("Women's Racers Net Times - All Years")
MeanTime_df <- data.frame(matrix(ncol = 2, nrow = 0))
x <- c("Year", "Mean Time")
colnames(MeanTime_df) = x
MeanTime_df[nrow(MeanTime_df) + 1,] = c("1999",mean(women_1999_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2000",mean(women_2000_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2001",mean(women_2001_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2002",mean(women_2002_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2003",mean(women_2003_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2004",mean(women_2004_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2005",mean(women_2005_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2006",mean(women_2006_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2007",mean(women_2007_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2008",mean(women_2008_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2009",mean(women_2009_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2010",mean(women_2010_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2011",mean(women_2011_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("2012",mean(women_2012_df$Net_Conv))
MeanTime_df[nrow(MeanTime_df) + 1,] = c("Total",mean(women_combined_df$Net_Conv))
as.data.table(MeanTime_df)
# Women's race time distribution
# We can see times are generally the same across years, except for the outlier year in 2011 which was slightly higher
Year_Sel <- c('1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012')
women_combined_df %>%
filter(Net_Conv > 18 & Year == Year_Sel) %>%
ggplot() +
geom_density(aes(x = Net_Conv,group = factor(Year), fill=factor(Year), alpha = 0.5)) +
ggtitle("Women's Race Time - All Years - Distribution") +
labs(fill = "Year") +
geom_vline(aes(xintercept=mean(Ag)), color="red", linetype="dashed", size=1)
# get total count of racers in 2006
nrow(women_2006_df)
# get number of racers under the mean of 22
nrow((women_2006_df[which(women_2006_df$Ag < 22), ]))
# get total count of racers in 2006
nrow(women_2006_df)
# get number of racers under the mean of 22
nrow((women_2006_df[which(women_2006_df$Ag < 22), ]))
# Load necessary package libraries
#install.packages("data.table")
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("tidyverse")
library(data.table)
library(tidyverse)
#library(plyr)
#library(tidyr)
#library(dplyr)
library(ggplot2)
#install.packages("caret")
library(caret)
#install.packages("randomForest")
library(randomForest)
#install.packages("gbm")
library(gbm)
#install.packages("corrgram")
library(corrgram)
install.packages("corrplot")
library(corrplot)
install.packages("mltools")
library(mltools)
install.packages("ggraph")
library(ggraph)
library(igraph)
install.packages("tree")
install.packages("data.tree")
library(tree)
install.packages("maptree")
library(maptree)
# Load necessary package libraries
#install.packages("data.table")
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("tidyverse")
library(data.table)
library(tidyverse)
#library(plyr)
#library(tidyr)
#library(dplyr)
library(ggplot2)
#install.packages("caret")
library(caret)
#install.packages("randomForest")
library(randomForest)
#install.packages("gbm")
library(gbm)
#install.packages("corrgram")
library(corrgram)
install.packages("corrplot")
library(corrplot)
install.packages("mltools")
library(mltools)
install.packages("ggraph")
library(ggraph)
library(igraph)
install.packages("tree")
install.packages("data.tree")
install.packages("mltools")
# Load necessary package libraries
library(data.table)
library(tidyverse)
#install.packages("caret")
library(caret)
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
#install.packages("randomForest")
library(randomForest)
#install.packages("gbm")
library(gbm)
#install.packages("corrgram")
library(corrgram)
library(corrplot)
#install.packages("skimr")
library(skimr)
#install.packages("rattle")
library(rattle)
library(RColorBrewer)
#install.packages("ROCR")
library(ROCR)
library(ranger)
#install.packages("broom")
library(broom)
#install.packages("e1071")
library("e1071")
# Define Helper functions
detectNA <- function(inp) {
sum(is.na(inp))
}
detectCor <- function(x) {
cor(as.numeric(emailDFrp[, x]),
as.numeric(emailDFrp$isSpam),
method="spearman")
}
# Load data
croom_wd = "C:/RAI/DS7333-QTW/CaseStudy3/"
barker_wd = "F:/SMU/DS7333/Repo/DS7333-QTW/CaseStudy3"
weinstock_wd = ""
setwd(barker_wd)
load("data.rda")
# summarize the data to look at counts, datatypes, and other information.
skim(emailDFrp)
#omit and NAs if found in the data set
emailDFrp = na.omit(emailDFrp)
skim(emailDFrp)
#Look at the frequency distribution of spam in our data
dfrQltyFreq <- summarise(group_by(emailDFrp, isSpam), count=n())
# plot the number of spam vs non-spam message in the data
ggplot(dfrQltyFreq, aes(x=isSpam, y=count)) +
geom_bar(stat="identity", aes(fill=count)) +
labs(title="Figure 1: isSpam Feature Frequency Distribution") +
labs(x="isSpam") +
labs(y="Counts")
emailDFrp %>%
ggplot(mapping = aes(x= isInReplyTo, fill = isSpam))+
geom_bar() +
labs(title="Figure 1b: isSpam vs. isinReplyTo Values") +
labs(x="isinReplyTo") +
labs(y="Counts")
emailDFrp %>%
ggplot(mapping = aes(x= priority, fill = isSpam))+
geom_bar() +
labs(title="Figure 1c: isSpam vs. priority Values") +
labs(x="Priority") +
labs(y="Counts")
emailDFrp %>%
ggplot(mapping = aes(x= isPGPsigned, fill = isSpam))+
geom_bar() +
labs(title="Figure 1d: isSpam vs. isPGPSigned Values") +
labs(x="isPGPSigned") +
labs(y="Counts")
# find correlations
Corr_DF <- abs(sapply(colnames(emailDFrp), detectCor)) #absolute value
summary(Corr_DF)
# One Hot Encode the dataframe to run correlation plots
OHE_emailDRrp = copy(emailDFrp)
cols <- sapply(OHE_emailDRrp, is.factor)
#convert all the factors to character values
OHE_emailDRrp[,cols] <- lapply(OHE_emailDRrp[,cols], function(x) as.character(x))
#convert the character value t/f to 1/0 respectively
OHE_emailDRrp[,cols] <- lapply(OHE_emailDRrp[,cols], function(x) gsub("T", "1", x))
OHE_emailDRrp[,cols] <- lapply(OHE_emailDRrp[,cols], function(x) gsub("F", "0", x))
#convert the character 1/0 to numberis
OHE_emailDRrp[,cols] <- lapply(OHE_emailDRrp[,cols], function(x) as.numeric(x))
corrplot(cor(OHE_emailDRrp[c(2:10,1)]))
corrplot(cor(OHE_emailDRrp[c(10:20,1)]))
corrplot(cor(OHE_emailDRrp[c(20:30,1)]))
# build out training and test data. We'll use an 80/20 split to start
set.seed(100)
cntTrainRecs = createDataPartition(y=emailDFrp$isSpam,p=0.8,list=FALSE)
train_df = emailDFrp[cntTrainRecs,]
test_df = emailDFrp[-cntTrainRecs,]
dim(train_df)
dim(test_df)
model = rpart(formula=isSpam~., data=train_df,method="class")
fancyRpartPlot(model,caption="Initial Tree")
predTest = predict(object=model, newdata=test_df, type="class")
confusionMatrix(data=predTest, reference=test_df$isSpam)
plotcp(model)
pruneModel = prune(model, cp=model$cptable[which.min(model$cptable[,"xerror"]),"CP"])
fancyRpartPlot(pruneModel,caption="Pruned Tree")
predTest = predict(object=pruneModel, newdata=test_df, type="class")
confusionMatrix(data=predTest, reference=test_df$isSpam)
set.seed(100)
cv5 = createMultiFolds(train_df$isSpam,k=5,times=5)
control = trainControl(method="repeatedcv", number=5, repeats=5, index=cv5)
modelCV = train(x=train_df[,-1],y=train_df[,1], method="rpart", tuneLength=30,trControl=control)
fancyRpartPlot(modelCV$finalModel, caption="CV Tree - Initial")
predTest = predict(object=modelCV$finalModel, newdata=test_df, type="class")
confusionMatrix(data=predTest, reference=test_df$isSpam)
#Build out random forest for analysis
set.seed(100)
#Mtry = sqrt(ncol(emailDFrp)-2)
Ntrees = 500
#track the processing time for grins
startTime = proc.time()
RFModel = randomForest(isSpam~.-isSpam,data=train_df,ntree=Ntrees, importance=TRUE)
endTime = proc.time()
# Display the model for accuracy understanding
RFModel
# Determine which factors have the most importance
#importance(RFModel)
#NOTE: Plotting the top 15 variables here for readability. most trail off under 30ish
varImpPlot(RFModel,main="Variable Importance Plot",n.var=15)
# Build out a confusion matrix for analysis
predictVal <- predict(RFModel, newdata=test_df)
CM_Result  <- confusionMatrix(predictVal,test_df$isSpam)
CM_Result
# Defines our parameters that will be used
gs <- list(minsplit = c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30),
maxdepth = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13)) %>%
cross_df() # Convert to data frame grid
# Our tree function
mod <- function(...) {
rpart(formula=isSpam~., data=train_df, ,method="class", control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
# Create an accuracy function to measure results
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test_features, type = "class")
mean(predicted == test_labels)
}
test_features <- train_df %>% select(-isSpam)
test_labels   <- train_df$isSpam
gs <- gs %>%
mutate(test_accuracy = map_dbl(fit, compute_accuracy,
test_features, test_labels))
# Arrange the results to display the highest accuracy
gs <- gs %>% arrange(desc(test_accuracy), desc(minsplit), maxdepth)
gs
gs_model = rpart(formula=isSpam~., data=train_df,method="class", minsplit = 2, maxdepth=13)
fancyRpartPlot(gs_model,caption="Grid Search Tree")
