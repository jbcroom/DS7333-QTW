{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QTW Case Study 5 - Missing Data Analysis with California Housing Data\n",
    "### Jayson Barker, Brandon Croom, Shane Weinstock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "#### Missing data (or missing values) occur when no data value is stored for a variable in an observation. To have missing data in a dataset is a common occurrence which can have profound effects on drawable conclusions from that data. There are several problems that can stem from having missing data in a dataset. First, missing data reduces statistical power, which refers to the probability that the hypothesis test will reject the null hypothesis when it is false. Second, missing data can cause bias in the estimations of parameters. Third, the representativeness of the sample used in analysis is reduced by missing data. Fourth, missing data may complicate the analysis by forcing the analyst to make assumptions on how to work with the data. Each of these distortions may threaten the validity of the conclusions.\n",
    "\n",
    "#### There are three types of missing data that typically occur in data sets. The definitions of these three types is based on the reasons the data is missing.\n",
    "\n",
    "#### Missing completely at random (MCAR) is defined as data that is missing without any specific reason; that is if the events that lead to any particular data being missing are independent both of observable variables and unobservable parameters of interest, and are entirely at random. MCAR data does allow any analysis to be unbiased given the random nature of the missing values. In practice, MCAR data is rare.\n",
    "\n",
    "#### Missing at random (MAR) occurs whe the missingness of the data is not random, but when it can be fully accounted for by observations with complete information. An example, of MAR would be a study on IQ and income, if participants with above average IQs tend to skip questions related to salary, analysis that do not take this into account may find a false relationship between IQ and salary. MAR data can introduce parameter bias if not detected. \n",
    "\n",
    "#### Missing not at random (MNAR) data occurs when there is a reason the data is missing. Extending on the example above if those with high IQs failed to answer the salary questions because of their IQ's the missingness of the salary data could be classified as MNAR\n",
    "\n",
    "#### Over the course of this report, we will leverage the California Housing data set provided as a part of the SKLearn package to show the impacts of these types of missing data on analysis. A baseline linear regression model will be built on the data set. Then the various missing data classifications will be executed on the data and the model re-evaluated to show the impacts on the model when compared to the baseline model. \n",
    "\n",
    "#### For those readers who want to understand the code used in this notebook, click the \"Show Inputs\" button below to display all of the cells containing code used in this analysis. Re-running the Jupyter cell will hide the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style id=hide>div.input{display:none;}</style><button type=\"button\"onclick=\"var myStyle = document.getElementById('hide').sheet;myStyle.insertRule('div.input{display:inherit !important;}', 0);\">Show inputs</button>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run me to hide code cells\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(r\"\"\"<style id=hide>div.input{display:none;}</style><button type=\"button\"onclick=\"var myStyle = document.getElementById('hide').sheet;myStyle.insertRule('div.input{display:inherit !important;}', 0);\">Show inputs</button>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "#### The California Housing data set is provided as part of the SKLearn package. Based on the description from the SKLearn website (https://scikit-learn.org/stable/datasets/index.html#real-world-datasets), the data set was obtained from the StatLib repository. The data set was derived from the 1990 US census. Each row in the data set is equal to a census block group. A block group is the smallest geographical unit that the US Census Bureau publishes sample data. The typical population in a block group is between 600 and 3000 people. The dataset contains 20,640 samples, 8 continuous features and no missing values. The features defined in the data are:\n",
    "\n",
    "- MedInc - Median Income in block\n",
    "- HouseAge - Median house age in block\n",
    "- AveRooms - Average number of rooms\n",
    "- AveBedrms - Average number of bedrooms\n",
    "- Population - Block population\n",
    "- AveOccup - Average house occupancy\n",
    "- Latitude - House Block Latitude\n",
    "- Longitude - House Block Longitude\n",
    "\n",
    "#### After loading the data set summary statistics are gathered for a quick analysis. The target variable is not initially inluded in the dataset and has been combined into the dataframe to obtain summary statistics.\n",
    "\n",
    "#### A quick review of these summary statistics shows that for the most part values seem reasonable. The counts in each feature column match the counts specified by the SKLearn library definition. Max values on a few columns (AveRooms, AveBedrms, and AveOccup) look suspect as they seem extremely high. These may need further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture warn\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from sklearn.datasets import california_housing\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import r2_score,adjusted_rand_score\n",
    "from sklearn.impute import SimpleImputer \n",
    "import ipywidgets as widgets\n",
    "from IPython import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelMetrics(testType, percentData, y_test, y_pred):\n",
    "\n",
    "    metricNames = ['r2_score',\n",
    "              'mean_squared_error',\n",
    "              'explained_variance_score', \n",
    "              'mean_absolute_error',\n",
    "              'median_absolute_error'\n",
    "                 ]\n",
    "    regMetrics = [sklearn.metrics.r2_score,\n",
    "                  sklearn.metrics.mean_squared_error,\n",
    "                  sklearn.metrics.explained_variance_score, \n",
    "                  sklearn.metrics.mean_absolute_error,\n",
    "                  sklearn.metrics.median_absolute_error\n",
    "                 ]\n",
    "\n",
    "    scores = {}\n",
    "    \n",
    "    scores['Test'] = testType\n",
    "    scores['Percent'] = percentData\n",
    "    \n",
    "    for name, metric in zip(metricNames, regMetrics):\n",
    "        scores[name] = round(metric(y_test, y_pred),3)\n",
    "        \n",
    "    return pd.DataFrame([scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>1.153956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude        prices  \n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704      2.068558  \n",
       "std       10.386050      2.135952      2.003532      1.153956  \n",
       "min        0.692308     32.540000   -124.350000      0.149990  \n",
       "25%        2.429741     33.930000   -121.800000      1.196000  \n",
       "50%        2.818116     34.260000   -118.490000      1.797000  \n",
       "75%        3.282261     37.710000   -118.010000      2.647250  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a full results dataframe\n",
    "df_results = []\n",
    "\n",
    "# download data and store to a data frame\n",
    "data = california_housing.fetch_california_housing()\n",
    "df = pd.DataFrame(data= data.data, columns=data.feature_names)\n",
    "\n",
    "# Fetch prices from the dataset\n",
    "p=data.target\n",
    "\n",
    "#converting prices to it's own dataframe for use later on in the split\n",
    "p_df=pd.DataFrame({\"prices\":p})\n",
    "\n",
    "#concatenating both dataframes to get the complete dataset\n",
    "calf_hous_df = pd.concat([df,p_df],axis=1)\n",
    "\n",
    "# Complete dataset\n",
    "calf_hous_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that summary analysis has been performed on the dataset, a check to verify that are are truly no missing values will occur. With the outut below, we can confirm that there are no missing values in any of the features or target variable of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "prices        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nulls\n",
    "calf_hous_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As an additional check, data correlation needs to be evaluated. Evaluating correlation allows for teasing out any colinear variables that may need to be removed from the model to improve performance. The heatmap below shows the correlation between features. AveRooms and AveBedrms are potentially collinear and may warrant removal from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14d50407520>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation heatmap\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Baseline Model\n",
    "\n",
    "####  Building a linear regression model to predict the housing price will provide a baseline model to compare against. This is a very simplistic model that provides a starting point and something to compare to as we move further along in the analysis.\n",
    "\n",
    "#### The data is initially split using an 80/20 train-test split. This produces a training data set of 16,512 rows x 8 columns. The corresponding predictor training set is also 16,512 rows x 1 column (prices).\n",
    "\n",
    "#### Using the test/train split data a linear regression model will be run to see how well housing prices can be predicted. The model will be evaluated on the R-squared metric. R-squared evalates the scatter of the data points around the fitted regression line. R-squared values are always between 0 and 100%. A value of 0% represents a model that does not explain any of the variation in the response variable, while a value of 100% represents a model that explains all of the variation in the response variable. As a model comparison metric the larger the R-squared metric the better the model. In addition to R-Squared metrics, other model metrics will also be captured and analyzed across all of the models. \n",
    "\n",
    "#### For the baseline linear regression model, the R-squared score is 33.4% (~0.3340). Given the low value this may not be the best model for predicting housing prices in California and further model manipulation may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data set using an 80/20 split\n",
    "calf_hous_df_2 = calf_hous_df[calf_hous_df.columns[~calf_hous_df.columns.isin(['prices'])]]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(calf_hous_df_2,p_df,test_size=0.2,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture x_train_capt\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture y_train_capt\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture lin_reg_capt\n",
    "# train the linear regression model\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the test data\n",
    "baseline_model_pred = baseline_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How accuratge is our baseline model? Let's return the R2 score\n",
    "df_results\n",
    "\n",
    "r2_baseline = r2_score(baseline_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('Baseline',0, baseline_model_pred, y_test))\n",
    "    \n",
    "# 0.334 is a pretty poor score for a baseline model. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Analysis\n",
    "\n",
    "#### In order to show the impact that missing data can have on models, the next few sections will evaluate the baseline linear regression model against the three missing data scenarios:\n",
    "\n",
    "    * Missing Completely At Random (MCAR)\n",
    "    * Missing At Random (MAR)\n",
    "    * Missing Not At Random (MNAR)\n",
    "\n",
    "#### Each of these scenarios will show the impact these missing data scenarios has on model performance based on how the missing values are handled.\n",
    "\n",
    "### Missing Completely At Random (MCAR) Analysis\n",
    "\n",
    "#### For the Missing Completely at Random analysis a single column, for this analysis HouseAge,  will be manipulated to replace 1%, 5%, 10%, 20%, 33% and 50% of the original data values with NaN at random. Once the data values for the various percentages have been randomly set to NaN, data imputation will be performed to \"fill in\" the missing values. The imputation method used on the HouseAge column will be using the mean value of the house age. Using the mean as the imputation method allows for maintaining the sample size and is relatively easy to perform. \n",
    "\n",
    "#### As a comparison metric for each of the imputation percentages the R-Squared metric will be used. It is expected that as the imputation percentage increases the R-Squared metric should decrease due to less variability in the data. \n",
    "\n",
    "#### The outputs below allow for ensuring data is manipulated based on the individual percentages defined above. The expectation is the percentages will be relatively close for the analysis with no large discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hold 1% of the records constant and replace with NAN\n",
    "df2 = calf_hous_df.copy()\n",
    "\n",
    "df2_1 = df.copy()\n",
    "df2_1.HouseAge[df2_1.HouseAge.sample(frac=(1/100)).index] = np.nan  \n",
    "\n",
    "# Hold 5% of the records constant and replace with NAN\n",
    "df2_5 = df.copy()\n",
    "df2_5.HouseAge[df2_5.HouseAge.sample(frac=(5/100)).index] = np.nan \n",
    "\n",
    "# Hold 10% of the records constant and replace with NAN\n",
    "df2_10 = df.copy()\n",
    "df2_10.HouseAge[df2_10.HouseAge.sample(frac=(10/100)).index] = np.nan \n",
    "\n",
    "# Hold 20% of the records constant and replace with NAN\n",
    "df2_20 = df.copy()\n",
    "df2_20.HouseAge[df2_20.HouseAge.sample(frac=(20/100)).index] = np.nan \n",
    "\n",
    "# Hold 33% of the records constant and replace with NAN\n",
    "df2_33 = df.copy()\n",
    "df2_33.HouseAge[df2_33.HouseAge.sample(frac=(33/100)).index] = np.nan \n",
    "\n",
    "# Hold 50% of the records constant and replace with NAN\n",
    "df2_50 = df.copy()\n",
    "df2_50.HouseAge[df2_50.HouseAge.sample(frac=(50/100)).index] = np.nan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 1%\n",
      "MedInc        0.000000\n",
      "HouseAge      0.998062\n",
      "AveRooms      0.000000\n",
      "AveBedrms     0.000000\n",
      "Population    0.000000\n",
      "AveOccup      0.000000\n",
      "Latitude      0.000000\n",
      "Longitude     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 1%\n",
    "print('Baseline NAs for 1%')\n",
    "print((df2_1.isna().sum()/len(df2_1))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 5%\n",
      "MedInc        0.0\n",
      "HouseAge      5.0\n",
      "AveRooms      0.0\n",
      "AveBedrms     0.0\n",
      "Population    0.0\n",
      "AveOccup      0.0\n",
      "Latitude      0.0\n",
      "Longitude     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 5%\n",
    "print('Baseline NAs for 5%')\n",
    "print((df2_5.isna().sum()/len(df2_5))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 10%\n",
      "MedInc         0.0\n",
      "HouseAge      10.0\n",
      "AveRooms       0.0\n",
      "AveBedrms      0.0\n",
      "Population     0.0\n",
      "AveOccup       0.0\n",
      "Latitude       0.0\n",
      "Longitude      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 10%\n",
    "print('Baseline NAs for 10%')\n",
    "print((df2_10.isna().sum()/len(df2_10))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 20%\n",
      "MedInc         0.0\n",
      "HouseAge      20.0\n",
      "AveRooms       0.0\n",
      "AveBedrms      0.0\n",
      "Population     0.0\n",
      "AveOccup       0.0\n",
      "Latitude       0.0\n",
      "Longitude      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 20%\n",
    "print('Baseline NAs for 20%')\n",
    "print((df2_20.isna().sum()/len(df2_20))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 33%\n",
      "MedInc         0.000000\n",
      "HouseAge      32.999031\n",
      "AveRooms       0.000000\n",
      "AveBedrms      0.000000\n",
      "Population     0.000000\n",
      "AveOccup       0.000000\n",
      "Latitude       0.000000\n",
      "Longitude      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 33%\n",
    "print('Baseline NAs for 33%')\n",
    "print((df2_33.isna().sum()/len(df2_33))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 50%\n",
      "MedInc         0.0\n",
      "HouseAge      50.0\n",
      "AveRooms       0.0\n",
      "AveBedrms      0.0\n",
      "Population     0.0\n",
      "AveOccup       0.0\n",
      "Latitude       0.0\n",
      "Longitude      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check baseline for NAs - 50%\n",
    "print('Baseline NAs for 50%')\n",
    "print((df2_50.isna().sum()/len(df2_50))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture impute_cap\n",
    "# Impute for the NANs and replace with the mean\n",
    "\n",
    "# Impute NANs - 1%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_1)\n",
    "imputer.transform(df2_1)\n",
    "\n",
    "# Impute NANs - 5%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_5)\n",
    "imputer.transform(df2_5)\n",
    "\n",
    "# Impute NANs - 10%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_10)\n",
    "imputer.transform(df2_10)\n",
    "\n",
    "# Impute NANs - 20%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_20)\n",
    "imputer.transform(df2_20)\n",
    "\n",
    "# Impute NANs - 33%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_33)\n",
    "imputer.transform(df2_33)\n",
    "\n",
    "# Impute NANs - 50%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_50)\n",
    "imputer.transform(df2_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 1%\n",
    "df2['HouseAge'] = df2_1['HouseAge']\n",
    "df2_v1 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v1_p = df2[['prices']]\n",
    "\n",
    "# Split 1%\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v1,df2_v1_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_1 = r2_score(impute_model_pred,y_test)\n",
    "\n",
    "df_results.append(getModelMetrics('MCAR',1, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 5%\n",
    "df2['HouseAge'] = df2_5['HouseAge']\n",
    "df2_v5 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v5_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v5,df2_v5_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_5 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MCAR',5, impute_model_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 10%\n",
    "df2['HouseAge'] = df2_10['HouseAge']\n",
    "df2_v10 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v10_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v10,df2_v10_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_10 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MCAR',10, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 20%\n",
    "df2['HouseAge'] = df2_20['HouseAge']\n",
    "df2_v20 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v20_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v20,df2_v20_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_20 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MCAR',20, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 33%\n",
    "df2['HouseAge'] = df2_33['HouseAge']\n",
    "df2_v33 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v33_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v33,df2_v33_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_33 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MCAR',33, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 50%\n",
    "df2['HouseAge'] = df2_50['HouseAge']\n",
    "df2_v50 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v50_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v50,df2_v50_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_50 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MCAR',50, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The table below shows the R-Squared results for each of the percentages of data imputation for the MCAR analysis. As expected the more data that is imputed the lower the R-Squared value. \n",
    "\n",
    "| Imputation |   |   R-Squared |\n",
    "|:----------:|:-:|:---------:|\n",
    "|     1%     |   | 33.4%     |\n",
    "|     5%     |   | 33.5%     |\n",
    "|     10%    |   | 33.1%     |\n",
    "|     20%    |   | 32.9%     |\n",
    "|     33%    |   | 32.5%     |\n",
    "|     50%    |   | 31.6%     |\n",
    "\n",
    "#### When compared to the baseline model R-Squared of 33.4% everything seems to be inline with the exception of the 5% imputation model. As more of the missing data is replaced with the mean the data values in the HouseAge column become more alike and thus the R-Squared values decrease. At 1% imputation this does not have a huge impact and is inline with the baseline model. At 50% imputation there is an impact and the R-Squared metrics differ. Comparing the MCAR models across themselves the impact of the imputation is evident as the values drop as more data is imputed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing At Random (MAR) Analysis\n",
    "\n",
    "#### For the Missing At Random (MAR) Analysis two different columns will be selected and data will be missing at random when controlled for by a third column. For example, if variable Z is > 30, then variables X and Y are randomly missing). The analysis will be performed on data percentages of 10%, 20% and 20% of missing data. These data sets will then be fit to the linear regression model and compared against the baseline model. \n",
    "\n",
    "#### In order to create the missing at random data the HouseAge and AveRoom columns were selected as the columns to make randomly missing. These columns will be marked missing based on the population field. If the population is greater than 1425, the mean of the population field,  then the HouseAge and AveRoom columns will be marked as missing. As was done previously, the mean will be used as the imputation method for the missing data. \n",
    "\n",
    "#### The outputs below allow for ensuring data is manipulated based on the individual percentages defined above. The expectation is the percentages will be relatively close for the analysis with no large discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 10%\n",
      "MedInc        0.000000\n",
      "HouseAge      3.643411\n",
      "AveRooms      3.643411\n",
      "AveBedrms     0.000000\n",
      "Population    0.000000\n",
      "AveOccup      0.000000\n",
      "Latitude      0.000000\n",
      "Longitude     0.000000\n",
      "prices        0.000000\n",
      "dtype: float64\n",
      "\n",
      "Baseline NAs for 20%\n",
      "MedInc        0.000000\n",
      "HouseAge      7.286822\n",
      "AveRooms      7.286822\n",
      "AveBedrms     0.000000\n",
      "Population    0.000000\n",
      "AveOccup      0.000000\n",
      "Latitude      0.000000\n",
      "Longitude     0.000000\n",
      "prices        0.000000\n",
      "dtype: float64\n",
      "\n",
      "Baseline NAs for 30%\n",
      "MedInc         0.000000\n",
      "HouseAge      10.935078\n",
      "AveRooms      10.935078\n",
      "AveBedrms      0.000000\n",
      "Population     0.000000\n",
      "AveOccup       0.000000\n",
      "Latitude       0.000000\n",
      "Longitude      0.000000\n",
      "prices         0.000000\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_var = df2.Population >= 1425\n",
    "cols_var = ['HouseAge','AveRooms']\n",
    "\n",
    "# 10% run\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3_10 = df2.copy()\n",
    "df3_10.loc[df3_10.loc[filter_var].sample(frac=(10/100)).index, cols_var] = np.nan\n",
    "\n",
    "# Check baseline for NAs - 10%\n",
    "print('Baseline NAs for 10%')\n",
    "print((df3_10.isna().sum()/len(df3_10))*100)\n",
    "print('')\n",
    "\n",
    "# 20% run\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3_20 = df2.copy()\n",
    "df3_20.loc[df3_20.loc[filter_var].sample(frac=(20/100)).index, cols_var] = np.nan\n",
    "\n",
    "# Check baseline for NAs - 20%\n",
    "print('Baseline NAs for 20%')\n",
    "print((df3_20.isna().sum()/len(df3_20))*100)\n",
    "print('')\n",
    "\n",
    "# 30% run\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3_30 = df2.copy()\n",
    "df3_30.loc[df3_30.loc[filter_var].sample(frac=(30/100)).index, cols_var] = np.nan\n",
    "\n",
    "# Check baseline for NAs - 30%\n",
    "print('Baseline NAs for 30%')\n",
    "print((df3_30.isna().sum()/len(df3_30))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture impute2_capt\n",
    "\n",
    "# Impute 10% run\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df3_10)\n",
    "imputer.transform(df3_10)\n",
    "\n",
    "# Impute 20% run\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df3_20)\n",
    "imputer.transform(df3_20)\n",
    "\n",
    "# Impute 30% run\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df3_30)\n",
    "imputer.transform(df3_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 10%\n",
    "df3['HouseAge'] = df3_10['HouseAge']\n",
    "df3['AveRooms'] = df3_10['AveRooms']\n",
    "df3_v10 = df3[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df3_v10_p = df3[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df3_v10,df3_v10_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_3_10 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MAR',10, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 20%\n",
    "df3['HouseAge'] = df3_20['HouseAge']\n",
    "df3['AveRooms'] = df3_20['AveRooms']\n",
    "df3_v20 = df3[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df3_v20_p = df3[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df3_v20,df3_v20_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_3_20 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MAR',20, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 30%\n",
    "df3['HouseAge'] = df3_30['HouseAge']\n",
    "df3['AveRooms'] = df3_30['AveRooms']\n",
    "df3_v30 = df3[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df3_v30_p = df3[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df3_v30,df3_v30_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_3_30 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MAR',30, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The table below shows the R-Squared results for each of the percentages of data imputation for the MAR analysis. As expected, the more data that is imputed the lower the R-Squared value. \n",
    "\n",
    "| Imputation |   |   R-Squared |\n",
    "|:----------:|:-:|:---------:|\n",
    "|     10%     |   | 31.6%     |\n",
    "|     20%     |   | 31.5%     |\n",
    "|     30%    |   | 31.3%     |\n",
    "\n",
    "#### When compared to the baseline model R-Squared of 33.4%, everything seems to be inline with the expectations that these models will not perform as well as the baseline model. As more of the missing data is replaced with the mean the data values in the HouseAge and AveRooms columns become more alike and thus the R-Squared values decrease. At 10% imputation there is an immediate difference between this model and the baseline model. This difference continues when comparing all models to the baseline model. Comparing within the models built for the MAR analysis, the R-Squared values are all fairly close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Not At Random (MNAR) Analysis\n",
    "\n",
    "#### For the Missing Not At Random (MNAR) Analysis a single column will be selected and data will be missing not at random for this column. The analysis will be performed only on a 25% of missing data for the target column. These data sets will then be fit to the linear regression model and compared against the baseline model. \n",
    "\n",
    "#### In order to create the missing not at random data the HouseAge column was selected as the column for missing data. HouseAge values over 28, the mean of the HouseAge, were marked as missing data. As was done previously, the mean will be used as the imputation method for the missing data. \n",
    "\n",
    "#### The outputs below allow for ensuring data is manipulated based on the individual percentages defined above. The expectation is the percentages will be relatively close for the analysis with no large discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NAs for 25%\n",
      "MedInc         0.0\n",
      "HouseAge      25.0\n",
      "AveRooms       0.0\n",
      "AveBedrms      0.0\n",
      "Population     0.0\n",
      "AveOccup       0.0\n",
      "Latitude       0.0\n",
      "Longitude      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df2 = calf_hous_df.copy()\n",
    "\n",
    "NANcols = ['HouseAge']\n",
    "mask = df2['HouseAge'] > 28\n",
    "\n",
    "df2_25 = df.copy()\n",
    "df2_25.loc[df2_25.loc[mask].sample(frac=(25/100)).index, NANcols] = np.nan\n",
    "\n",
    "# Check baseline for NAs - 25%\n",
    "print('Baseline NAs for 25%')\n",
    "print((df2_25[mask].isna().sum()/len(df2_25[mask]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture impute3_capt\n",
    "# Impute NANs - 25%\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "imputer.fit(df2_25)\n",
    "imputer.transform(df2_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace existing HouseAge column with imputed column - 25%\n",
    "df2['HouseAge'] = df2_25['HouseAge']\n",
    "df2_v25 = df2[['MedInc', 'HouseAge','AveRooms','AveBedrms','Population','AveOccup','Latitude','Longitude']]\n",
    "df2_v25_p = df2[['prices']]\n",
    "\n",
    "# Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df2_v25,df2_v25_p,test_size=0.2,random_state=7)\n",
    "\n",
    "# train the linear regression model\n",
    "impute_model = LinearRegression()\n",
    "impute_model.fit(x_train,y_train)\n",
    "\n",
    "# predict using the test data\n",
    "impute_model_pred = impute_model.predict(x_test)\n",
    "\n",
    "# How accuratge is our model? R2\n",
    "r2_impute_5 = r2_score(impute_model_pred,y_test)\n",
    "df_results.append(getModelMetrics('MNAR',25, impute_model_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The MNAR model generates an R-Squared score of 32.5%. When compared to the baseline model R-Squared of 33.4% everything seems to be inline with the expectations that the MNAR model will not perform as well as the baseline model. As with the other models, the more the mean data is used the more similarities are available within the model which results in a lower R-squared score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "#### Throughout the analysis R-Squared has been the metric of choice to compare the models against each other. As previously noted other metrics were also captured for comparison. The other metrics captured were:\n",
    "\n",
    "- Mean Squared Error - estimates the average squared difference between the estimated values and the actual value.\n",
    "\n",
    "- Explained Variance Score - used to measure the discrepance between the model and actual data. Higher percentages (scores) indicate better predictions.\n",
    "\n",
    "- Mean Absolute Error - is the measure of the magnitude of the errors between the predicted value and the actual value.\n",
    "    \n",
    "- Median Absolute Error - similar to mean absolute error, except leveraging the median\n",
    " \n",
    "#### The table below shows the results for each of the metrics defined above, as well as R-Squared, for each of the models defined in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d1fcac32e3494cbbce927780c7eded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results_merged = pd.concat(df_results, ignore_index=True)\n",
    "\n",
    "widget1 = widgets.Output()\n",
    "with widget1:\n",
    "    display.display(df_results_merged)\n",
    "    \n",
    "hbox = widgets.HBox([widget1])\n",
    "hbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar results are seen with the other metrics as were seen with the R-Squared metric. For example, the Mean Squared Error values continue to increase as more data is manipulated through the various tests and data percentage changes. A similar pattern is seen with the explained variance score metric, the values continue to go lower as more data is manipulated. As a reminder, explained variance score typically looks at higher values to explain variance. \n",
    "\n",
    "#### In conclusion the impact of missing data on the model and the model comparison metrics based on the type of data missingness is very apparent. There is no replacement for the actual data, although there are some solutions. Depending on the study, attempting to correct for these various missing variables could be the right solution, especially in very small sample sizes. Otherwise, advising others on how to collect or suggesting to improve data collection might be most beneficial before coming to a conclusion. If a solution must be developed, exploring variables fully and imputing or correcting for the smallest amount will yield the best results (based on our work above, but maybe not empirically across every situation). With all of these situations, the more reliant we are on the mean for completing our data, the less statistical power our models will have. Even in much larger studies and models, there are ways to mathematically optimize the model through limiting the size of the data, this could also be considered when a larger dataset has missing data as well. Most importantly, the above methods show us that imputation and completing the different types of missing data will have profound effects on our data. In most cases, we will always be trying to avoid implementing these techniques, however they are useful when no other option exists to draw significant statistical inferences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
